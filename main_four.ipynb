{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone-client -quiet\n",
    "%pip install python-dotenv -quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623494db-40e1-44ee-9890-26f24e1dd55b\n"
     ]
    }
   ],
   "source": [
    "## Load API key from .env\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "## Error Handling for API key retreival\n",
    "try: \n",
    "            \n",
    "    load_dotenv()\n",
    "\n",
    "    PC_KEY = os.getenv('PINECONE_API_KEY')\n",
    "    print(PC_KEY)\n",
    "\n",
    "    if not PC_KEY:\n",
    "        raise ValueError(\"PINECONE_API_KEY not found in .env file\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\legal_document_reccomender\\.venv\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PC_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['idx-one', 'idx-two']\n",
      "Collections: []\n"
     ]
    }
   ],
   "source": [
    "## View current indexes in Pinecone \n",
    " \n",
    "print(f\"Indexes: {pc.list_indexes().names()}\")\n",
    "print(f\"Collections: {pc.list_collections().names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not create index. Index with name \"idx-two\" already exists. \n"
     ]
    }
   ],
   "source": [
    "## This POC currently only uses 1 index. As we scale up our data and decide how we can partition different legal documents, we can scale horizontally. \n",
    "## In this demo, there are only a handful of documents, enabling efficiency with a single index\n",
    "\n",
    "\n",
    "index_name = \"idx-two\"\n",
    "\n",
    "## Embedding model is [BERT large model (uncased)], which outputs vectors of [768] dimensions\n",
    "## Cosine similarity so search is not skewed by magnitude\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n",
    "else: \n",
    "    print(f'Error: Could not create index. Index with name \"{index_name}\" already exists. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text file to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textFileToString(filepath):\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        str = file.read()\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Strings to Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Projects\\legal_document_reccomender\\.venv\\Scripts\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -Q\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch -Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# # Load the pre-trained BERT model and tokenizer\n",
    "# model_name = 'bert-large-uncased'\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(str):\n",
    "    inputs = tokenizer(str, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    vector = last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return vector.tolist() ## return as list (len 768\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add first vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT JUSTICE Drug Enforcement Administration 21 CFR Part 1308 [ Docket . DEA–1362 ; A.G. Order . 5931–2024 ] Schedules Controlled Substances : R\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BertForPreTrainingOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(s[:\u001b[38;5;241m150\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# convert string to embedding\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m vector \u001b[38;5;241m=\u001b[39m \u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# check embedding is correct size\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vector) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m768\u001b[39m:\n",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m, in \u001b[0;36membed\u001b[1;34m(str)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      4\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m----> 5\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\n\u001b[0;32m      6\u001b[0m vector \u001b[38;5;241m=\u001b[39m last_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vector\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertForPreTrainingOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-11137.txt\"\n",
    "# File Description: Schedules of Controlled Substances: Rescheduling of Marijuana\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-11137\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-21',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 44597\",\n",
    "    'page_start': 44597,\n",
    "    'page_end':44622,\n",
    "    'cfr': \"21 CFR 1308\", \n",
    "    'document_number': \"2024-11137\", \n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Second Vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT EDUCATION [ Docket ID ED–2024–OPE–0072 ] Request Information Identifying Tracking Data Related Early Childhood Education Providers AGENCY :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-13446.txt\"\n",
    "# Request for Information on Identifying and Tracking Data Related to Early Childhood Education Providers\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13446\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-20',\n",
    "    'document_type': 'Notice', \n",
    "    'document_citation': \"89 FR 51878\",\n",
    "    'page_start': 51878,\n",
    "    'page_end':51878,\n",
    "    'document_number': \"2024-13446\", \n",
    "    'agency': \"DEPARTMENT OF EDUCATION\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT AGRICULTURE Agricultural Marketing Service 7 CFR Part 175 [ Doc . . AMS–LP–24–0012 ] RIN 0581–AE29 Greenhouse Gas Technical Assistance Prov\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-11424.txt\"\n",
    "# Greenhouse Gas Technical Assistance Provider and Third-Party Verifier Program\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-11424\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-29',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 46335\",\n",
    "    'page_start': 46335,\n",
    "    'page_end':46336,\n",
    "    'document_number': \"2024-11424\", \n",
    "    'agency': \"DEPARTMENT OF AGRICULTURE\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding 4th doc to Pinecone\n",
    "\n",
    "\n",
    "Executive Order 14123 of June 14, 2024\n",
    "White House Council on Supply Chain Resilience \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidential Documents 51949 Federal Register Vol . 89 , . 120 Friday , June 21 , 2024 Title 3— President Executive Order 14123 June 14 , 2024 White H\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-13810.txt\"\n",
    "\n",
    "# Executive Order 14123 of June 14, 2024\n",
    "# White House Council on Supply Chain Resilience \n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13810\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-21',\n",
    "    'document_type': 'Presidential Document', \n",
    "    'document_citation': \"89 FR 51949\",\n",
    "    'page_start': 51949,\n",
    "    'page_end':51953,\n",
    "    'document_number': \"2024-13810\", \n",
    "    'agency': \"EXECUTIVE OFFICE OF THE PRESIDENT\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding 5th vector to Pinecone\n",
    "\n",
    "Continuation of the National Emergency With Respect to Belarus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidential Documents 51197 Federal Register Vol . 89 , . 116 Friday , June 14 , 2024 Title 3— President Notice June 13 , 2024 Continuation National \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-13361.txt\"\n",
    "\n",
    "# Executive Order \n",
    "# Continuation of the National Emergency With Respect to Belarus\n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13361\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-14',\n",
    "    'document_type': 'Presidential Document', \n",
    "    'document_citation': \"89 FR 51197\",\n",
    "    'page_start': 51197,\n",
    "    'page_end':51198,\n",
    "    'document_number': \"2024-13361\", \n",
    "    'agency': \"EXECUTIVE OFFICE OF THE PRESIDENT\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federal Register / Vol . 89 , . 92 / Friday , May 10 , 2024 / Proposed Rules 40439 DEPARTMENT COMMERCE Patent Trademark Office 37 CFR Part 1 [ Docket \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-10166.txt\"\n",
    "\n",
    "# Proposed Rule from PTO \n",
    "# Terminal Disclaimer Practice To Obviate Nonstatutory Double Patenting\n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-10166\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-10',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 40439\",\n",
    "    'page_start': 40439,\n",
    "    'page_end':40449,\n",
    "    'document_number': \"2024-10166\", \n",
    "    'agency': [\"DEPARTMENT OF COMMERCE\", \"PATENT TRADEMARK OFFICE\"], \n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section FEDERAL REGISTER contains notices public proposed issuance rules regulations . purpose notices give interested persons opportunity participate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 9-11 Response and Biometric Entry-Exit Fee for H-1B and L-1 Visas\n",
    "\n",
    "## Department of Homeland Security\n",
    "## US Customs and Border Protection\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"cleaned_texts\\\\2024-12396.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-12396\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-07-08',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 48339\",\n",
    "    'page_start': 48339,\n",
    "    'page_end':48348,\n",
    "    'document_number': \"2024-12396\", \n",
    "    'agency': [\"Department of Homeland Security\", \"U.S. Customs and Border Protection\"]\n",
    "    \n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying new document to find relevant documents in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['idx-one']\n",
      "Collections: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Indexes: {pc.list_indexes().names()}\")\n",
    "print(f\"Collections: {pc.list_collections().names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47536 Federal Register / Vol . 89 , . 107 / Monday , June 3 , 2024 / Notices DEPARTMENT COMMERCE International Trade Administration [ Docket . 240530–\n"
     ]
    }
   ],
   "source": [
    "filepath = \"cleaned_texts\\\\2024-12240.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "query_vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "\n",
    "# # Print the IDs of similar documents and their distances (similarity scores)\n",
    "# for result in results:\n",
    "#     document_id = result.id\n",
    "#     distance = result.distance\n",
    "#     print(f\"Document ID: {document_id}, Distance: {distance}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x122e32dbf50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-11424', 'score': 0.986865401, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.985422194, 'values': []},\n",
       "             {'id': '2024-13810', 'score': 0.978325, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-11424', 'score': 0.986865401, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.985422194, 'values': []},\n",
       "             {'id': '2024-13810', 'score': 0.978325, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.976930618, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.972628117, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.96892792, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.960439682, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplicity , Sustainability Performance Modern Enterprise Managing data sprawl across on-premises infrastructure public cloud environments complex . T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-10166', 'score': 0.982084632, 'values': []},\n",
       "             {'id': '2024-13810', 'score': 0.980202138, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.972716212, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.962522805, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.948810637, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.947627962, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.937301755, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query HVF Blog\n",
    "\n",
    "filepath = \"cleaned_texts\\\\hvf_blog.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "query_vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "\n",
    "# # Print the IDs of similar documents and their distances (similarity scores)\n",
    "# for result in results:\n",
    "#     document_id = result.id\n",
    "#     distance = result.distance\n",
    "#     print(f\"Document ID: {document_id}, Distance: {distance}\")\n",
    "\n",
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly ! 's continuous stream completely random text , spanning 10,000 words : quiet corners forgotten alleys , shadows dance whispers ghosts , lie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-11137', 'score': 0.930486798, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.928763032, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.920468628, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.918843865, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.912454903, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.90340507, 'values': []},\n",
       "             {'id': '2024-13810', 'score': 0.88775456, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query completely random text\n",
    "\n",
    "## Query HVF Blog\n",
    "\n",
    "filepath = \"cleaned_texts\\\\random_text.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "query_vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "\n",
    "# # Print the IDs of similar documents and their distances (similarity scores)\n",
    "# for result in results:\n",
    "#     document_id = result.id\n",
    "#     distance = result.distance\n",
    "#     print(f\"Document ID: {document_id}, Distance: {distance}\")\n",
    "\n",
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-13810', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.0, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.0, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing empty Vector\n",
    "\n",
    "query_vector = [0] * 768\n",
    "\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-13810', 'score': 0.00620419858, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.00615712814, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.0059460029, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.00566380285, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.00390182505, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.00377147738, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.0020740605, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing empty Vector\n",
    "\n",
    "query_vector = [0.01] * 768\n",
    "\n",
    "if len(vector) != 768\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-13810', 'score': 0.00620420091, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.00615712535, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.0059460029, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.00566380285, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.00390182831, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.00377147365, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.00207405956, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing empty Vector\n",
    "\n",
    "query_vector = [1] * 768\n",
    "\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-13810', 'score': 0.00620420091, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.00615712535, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.0059460029, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.00566380285, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.00390182831, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.00377147365, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.00207405956, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparing empty Vector\n",
    "\n",
    "query_vector = [0.5] * 768\n",
    "\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74974196 0.72187032 0.46203671 0.61726079 0.94966722 0.77280042\n",
      " 0.07771156 0.03240993 0.20684468 0.2283955 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-13810', 'score': 0.00620420091, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.00615712535, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.0059460029, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.00566380285, 'values': []},\n",
       "             {'id': '2024-11137', 'score': 0.00390182831, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.00377147365, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.00207405956, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the length of the vector\n",
    "vector_length = 768\n",
    "\n",
    "# Create a vector of random values between 0 and 1\n",
    "vector = np.random.rand(vector_length)\n",
    "\n",
    "# Print the vector (first 10 elements for demonstration)\n",
    "print(vector[:10])  # Print the first 10 elements\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 768:\n",
    "    print(\"Vector length invalid\")\n",
    "    \n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
