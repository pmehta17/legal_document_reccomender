{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone-client -quiet\n",
    "%pip install python-dotenv -quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623494db-40e1-44ee-9890-26f24e1dd55b\n"
     ]
    }
   ],
   "source": [
    "## Load API key from .env\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "## Error Handling for API key retreival\n",
    "try: \n",
    "            \n",
    "    load_dotenv()\n",
    "\n",
    "    PC_KEY = os.getenv('PINECONE_API_KEY')\n",
    "    print(PC_KEY)\n",
    "\n",
    "    if not PC_KEY:\n",
    "        raise ValueError(\"PINECONE_API_KEY not found in .env file\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PC_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['idx-one']\n",
      "Collections: []\n"
     ]
    }
   ],
   "source": [
    "## View current indexes in Pinecone \n",
    " \n",
    "print(f\"Indexes: {pc.list_indexes().names()}\")\n",
    "print(f\"Collections: {pc.list_collections().names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not create index. Index with name \"idx-one\" already exists. \n"
     ]
    }
   ],
   "source": [
    "## This POC currently only uses 1 index. As we scale up our data and decide how we can partition different legal documents, we can scale horizontally. \n",
    "## In this demo, there are only a handful of documents, enabling efficiency with a single index\n",
    "\n",
    "\n",
    "index_name = \"idx-one\"\n",
    "\n",
    "## Embedding model is [BERT large model (uncased)], which outputs vectors of [1024] dimensions\n",
    "## Cosine similarity so search is not skewed by magnitude\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n",
    "else: \n",
    "    print(f'Error: Could not create index. Index with name \"{index_name}\" already exists. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text file to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textFileToString(filepath):\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        str = file.read()\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Strings to Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Program Files\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -Q\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch -Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(str):\n",
    "    inputs = tokenizer(str, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    vector = last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return vector.tolist() ## return as list (len 1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add first vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT OF JUSTICE\n",
      "Drug Enforcement Administration\n",
      "21 CFR Part 1308\n",
      "[Docket No. DEA–1362; A.G. Order No.\n",
      "5931–2024]\n",
      "Schedules of Controlled Substan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-11137.txt\"\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-11137\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-21',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 44597\",\n",
    "    'page_start': 44597,\n",
    "    'page_end':44622,\n",
    "    'cfr': \"21 CFR 1308\", \n",
    "    'document_number': \"2024-11137\", \n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Second Vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
