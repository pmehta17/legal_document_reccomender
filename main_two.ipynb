{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -u\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone-client -quiet\n",
    "%pip install python-dotenv -quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623494db-40e1-44ee-9890-26f24e1dd55b\n"
     ]
    }
   ],
   "source": [
    "## Load API key from .env\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "## Error Handling for API key retreival\n",
    "try: \n",
    "            \n",
    "    load_dotenv()\n",
    "\n",
    "    PC_KEY = os.getenv('PINECONE_API_KEY')\n",
    "    print(PC_KEY)\n",
    "\n",
    "    if not PC_KEY:\n",
    "        raise ValueError(\"PINECONE_API_KEY not found in .env file\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PC_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['idx-one']\n",
      "Collections: []\n"
     ]
    }
   ],
   "source": [
    "## View current indexes in Pinecone \n",
    " \n",
    "print(f\"Indexes: {pc.list_indexes().names()}\")\n",
    "print(f\"Collections: {pc.list_collections().names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not create index. Index with name \"idx-one\" already exists. \n"
     ]
    }
   ],
   "source": [
    "## This POC currently only uses 1 index. As we scale up our data and decide how we can partition different legal documents, we can scale horizontally. \n",
    "## In this demo, there are only a handful of documents, enabling efficiency with a single index\n",
    "\n",
    "\n",
    "index_name = \"idx-one\"\n",
    "\n",
    "## Embedding model is [BERT large model (uncased)], which outputs vectors of [1024] dimensions\n",
    "## Cosine similarity so search is not skewed by magnitude\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    ) \n",
    "else: \n",
    "    print(f'Error: Could not create index. Index with name \"{index_name}\" already exists. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text file to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textFileToString(filepath):\n",
    "\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        str = file.read()\n",
    "\n",
    "    return str\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Strings to Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <requirement specifier> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] -r <requirements file> [package-index-options] ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <vcs project url> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] [-e] <local project path> ...\n",
      "  c:\\Users\\pratham.mehta\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install [options] <archive url/path> ...\n",
      "\n",
      "no such option: -Q\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch -Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-large-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(str):\n",
    "    inputs = tokenizer(str, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    vector = last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return vector.tolist() ## return as list (len 1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add first vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT OF JUSTICE\n",
      "Drug Enforcement Administration\n",
      "21 CFR Part 1308\n",
      "[Docket No. DEA–1362; A.G. Order No.\n",
      "5931–2024]\n",
      "Schedules of Controlled Substan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-11137.txt\"\n",
    "# File Description: Schedules of Controlled Substances: Rescheduling of Marijuana\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-11137\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-21',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 44597\",\n",
    "    'page_start': 44597,\n",
    "    'page_end':44622,\n",
    "    'cfr': \"21 CFR 1308\", \n",
    "    'document_number': \"2024-11137\", \n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Second Vector to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT OF EDUCATION\n",
      "[Docket ID ED–2024–OPE–0072]\n",
      "Request for Information on Identifying\n",
      "and Tracking Data Related to Early\n",
      "Childhood Education Pro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-13446.txt\"\n",
    "# Request for Information on Identifying and Tracking Data Related to Early Childhood Education Providers\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13446\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-20',\n",
    "    'document_type': 'Notice', \n",
    "    'document_citation': \"89 FR 51878\",\n",
    "    'page_start': 51878,\n",
    "    'page_end':51878,\n",
    "    'document_number': \"2024-13446\", \n",
    "    'agency': \"DEPARTMENT OF EDUCATION\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPARTMENT OF AGRICULTURE\n",
      "Agricultural Marketing Service\n",
      "7 CFR Part 175\n",
      "[Doc. No. AMS–LP–24–0012]\n",
      "RIN 0581–AE29\n",
      "Greenhouse Gas Technical Assistance\n",
      "Pr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-11424.txt\"\n",
    "# Greenhouse Gas Technical Assistance Provider and Third-Party Verifier Program\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-11424\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-29',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 46335\",\n",
    "    'page_start': 46335,\n",
    "    'page_end':46336,\n",
    "    'document_number': \"2024-11424\", \n",
    "    'agency': \"DEPARTMENT OF AGRICULTURE\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding 4th doc to Pinecone\n",
    "\n",
    "\n",
    "Executive Order 14123 of June 14, 2024\n",
    "White House Council on Supply Chain Resilience \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidential Documents\n",
      "51949\n",
      "Federal Register\n",
      "Vol. 89, No. 120\n",
      "Friday, June 21, 2024\n",
      "Title 3—\n",
      "The President\n",
      "Executive Order 14123 of June 14, 2024\n",
      "Whi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-13810.txt\"\n",
    "\n",
    "# Executive Order 14123 of June 14, 2024\n",
    "# White House Council on Supply Chain Resilience \n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13810\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-21',\n",
    "    'document_type': 'Presidential Document', \n",
    "    'document_citation': \"89 FR 51949\",\n",
    "    'page_start': 51949,\n",
    "    'page_end':51953,\n",
    "    'document_number': \"2024-13810\", \n",
    "    'agency': \"EXECUTIVE OFFICE OF THE PRESIDENT\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding 5th vector to Pinecone\n",
    "\n",
    "Continuation of the National Emergency With Respect to Belarus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presidential Documents\n",
      "51197\n",
      "Federal Register\n",
      "Vol. 89, No. 116\n",
      "Friday, June 14, 2024\n",
      "Title 3—\n",
      "The President\n",
      "Notice of June 13, 2024\n",
      "Continuation of th\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-13361.txt\"\n",
    "\n",
    "# Executive Order \n",
    "# Continuation of the National Emergency With Respect to Belarus\n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-13361\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-06-14',\n",
    "    'document_type': 'Presidential Document', \n",
    "    'document_citation': \"89 FR 51197\",\n",
    "    'page_start': 51197,\n",
    "    'page_end':51198,\n",
    "    'document_number': \"2024-13361\", \n",
    "    'agency': \"EXECUTIVE OFFICE OF THE PRESIDENT\"\n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federal Register / Vol. 89, No. 92 / Friday, May 10, 2024 / Proposed Rules 40439\n",
      "DEPARTMENT OF COMMERCE\n",
      "Patent and Trademark Office\n",
      "37 CFR Part 1\n",
      "[Doc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-10166.txt\"\n",
    "\n",
    "# Proposed Rule from PTO \n",
    "# Terminal Disclaimer Practice To Obviate Nonstatutory Double Patenting\n",
    "\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-10166\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-05-10',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 40439\",\n",
    "    'page_start': 40439,\n",
    "    'page_end':40449,\n",
    "    'document_number': \"2024-10166\", \n",
    "    'agency': [\"DEPARTMENT OF COMMERCE\", \"PATENT TRADEMARK OFFICE\"], \n",
    "\n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This section of the FEDERAL REGISTER\n",
      "contains notices to the public of the proposed\n",
      "issuance of rules and regulations. The\n",
      "purpose of these notices is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 9-11 Response and Biometric Entry-Exit Fee for H-1B and L-1 Visas\n",
    "\n",
    "## Department of Homeland Security\n",
    "## US Customs and Border Protection\n",
    "\n",
    "\n",
    "\n",
    "filepath = \"texts\\\\2024-12396.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "vector_id = \"2024-12396\"\n",
    "\n",
    "metadata = {\n",
    "\n",
    "    'publication_date': '2024-07-08',\n",
    "    'document_type': 'Proposed Rule', \n",
    "    'document_citation': \"89 FR 48339\",\n",
    "    'page_start': 48339,\n",
    "    'page_end':48348,\n",
    "    'document_number': \"2024-12396\", \n",
    "    'agency': [\"Department of Homeland Security\", \"U.S. Customs and Border Protection\"]\n",
    "    \n",
    "}\n",
    "\n",
    "upsert_data = [(vector_id, vector, metadata)]\n",
    "\n",
    "# Upsert the data to the Pinecone index\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "index.upsert(upsert_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying new ocument to find relevant documents in our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: ['idx-one']\n",
      "Collections: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Indexes: {pc.list_indexes().names()}\")\n",
    "print(f\"Collections: {pc.list_collections().names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47536 Federal Register / Vol. 89, No. 107 / Monday, June 3, 2024 / Notices\n",
      "DEPARTMENT OF COMMERCE\n",
      "International Trade Administration\n",
      "[Docket No. 24053\n"
     ]
    }
   ],
   "source": [
    "filepath = \"texts\\\\2024-12240.txt\"\n",
    "\n",
    "\n",
    "# Read text file into string\n",
    "s = textFileToString(filepath)\n",
    "print(s[:150])\n",
    "\n",
    "# convert string to embedding\n",
    "query_vector = embed(s)\n",
    "\n",
    "# check embedding is correct size\n",
    "if len(vector) != 1024:\n",
    "    print(\"Vector length invalid\")\n",
    "\n",
    "\n",
    "# # Print the IDs of similar documents and their distances (similarity scores)\n",
    "# for result in results:\n",
    "#     document_id = result.id\n",
    "#     distance = result.distance\n",
    "#     print(f\"Document ID: {document_id}, Distance: {distance}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x1f7a158e2d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-11137', 'score': 0.972805679, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.97222805, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.972106159, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=3,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '2024-11137', 'score': 0.972921729, 'values': []},\n",
       "             {'id': '2024-10166', 'score': 0.97222805, 'values': []},\n",
       "             {'id': '2024-11424', 'score': 0.972106159, 'values': []},\n",
       "             {'id': '2024-13810', 'score': 0.959383905, 'values': []},\n",
       "             {'id': '2024-13361', 'score': 0.956893742, 'values': []},\n",
       "             {'id': '2024-13446', 'score': 0.944576442, 'values': []},\n",
       "             {'id': '2024-12396', 'score': 0.921917617, 'values': []}],\n",
       " 'namespace': '',\n",
       " 'usage': {'read_units': 5}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the query to Pinecone to find similar documents\n",
    "index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=10,\n",
    "    include_values=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
